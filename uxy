#!/usr/bin/env python3

#  Copyright (c) 2019 Martin Sustrik
#
#  Permission is hereby granted, free of charge, to any person obtaining a copy
#  of this software and associated documentation files (the "Software"),
#  to deal in the Software without restriction, including without limitation
#  the rights to use, copy, modify, merge, publish, distribute, sublicense,
#  and/or sell copies of the Software, and to permit persons to whom
#  the Software is furnished to do so, subject to the following conditions:
#  The above copyright notice and this permission notice shall be included
#  in all copies or substantial portions of the Software.
#  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
#  THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
#  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
#  IN THE SOFTWARE.

import argparse
import csv
import io
import itertools
import json
import re
import subprocess
import sys
import unicodedata
import yaml


################################################################################
# Infrastructure
################################################################################


def trim_newline(s):
  if s.endswith('\n'):
    return s[:-1]
  return s

def writeout(s):
 try:
   sys.stdout.write(s)
 except BrokenPipeError:
   # The next command in the pipeline is not interested in more data.
   # We can shut down cleanly.
   sys.exit(0)

ESCAPE_SEQUENCES1 = {
  't':  '\t',
  'n':  '\n',
  '"':  '"',
  '\\': '\\',
}


ESCAPE_SEQUENCES2 = {
  '\t':  't',
  '\n':  'n',
  '"':  '"',
  '\\': '\\',
}


# Convert uxy field into a string.
def decode_field(s):
  # Replace control characters by question marks.
  s = "".join((c if unicodedata.category(c)[0] != "C" else '?') for c in s)
  if not (s.startswith('"') and s.endswith('"')):
    return s
  # Quoted field.
  s = s[1:-1]
  # Expand escape sequences.
  f = ""
  j = 0
  while j < len(s):
    if s[j] == '\\':
      if j + 1 >= len(s):
        f += "?"
        j += 1;
        continue
      if s[j + 1] not in ESCAPE_SEQUENCES1:
        f += "?"
        j += 2
        continue
      f += ESCAPE_SEQUENCES1[s[j + 1]]
      j += 2
      continue
    f += s[j]
    j += 1
  return f


# Convert arbitrary string into a uxy field.
def encode_field(s):
  # Empty string converts to "".
  if s == "":
    return '""  '
  # Check whether the string contains any special characters.
  special = False
  if '"' in s or ' ' in s:
    special = True
  else:
    for c in s:
      if unicodedata.category(c)[0] == "C":
        special = True
        break
  if not special:
    return s
  # Quoted field is needed.
  f = '"'
  for c in s:
    if c in ESCAPE_SEQUENCES2:
      f += ESCAPE_SEQUENCES2[c]
      continue
    f += c
  return f + '"'

UNQUOTED = 1
QUOTED = 2
ESCAPE = 3
TRAILING = 4

# Given a line, this function splits it into individual uxy fields and
# field widths.
def split_fields_widths(s):
  fields = []
  widths = []
  state = TRAILING
  field = ""
  width = 0
  for c in s:
    if state == UNQUOTED:
      if c == ' ':
        width += 1
        state = TRAILING
      else:
        field += c
        width += 1
    elif state == QUOTED:
      if c == "\\":
        field += c
        width += 1
        state = ESCAPE
      elif c == '"':
        field += c
        width += 1
        state = TRAILING
      else:
        field += c
        width += 1      
    elif state == ESCAPE:
      field += c
      width += 1
      state = QUOTED
    elif state == TRAILING:
      if c == " ":
        width += 1
      else:
        if len(field) > 0:
          fields.append(field)
          widths.append(width)
        field = c
        width = 1
        if c == '"':
          state = QUOTED
        else:
          state = UNQUOTED
  if len(field) > 0:
    fields.append(field)
    widths.append(width)
  return (fields, widths)


# Given a line, this function splits it into individual uxy fields.
def split_fields(s):
  fields, _ = split_fields_widths(s)
  return fields


class Format:

  # Create a format from a list of fields.
  # The values of the fields will be used as column names.
  def __init__(self, fmt):
    self.fields, self.widths = split_fields_widths(fmt)

  # Adjust the format so that the fields fit in.
  def adjust(self, fields):
    for i in range(0, len(fields)):
       self.widths[i] = max(self.widths[i], len(fields[i]) + 1)

  # Renders the supplied fields according to the format.
  # If fields is None, it renders the header itself.
  def render(self, fields=None):
    if fields == None:
      fields = self.fields
    broken = False
    res = ""
    for i in range(0, len(fields)):
      if broken or len(fields[i]) + 1 > self.widths[i]:
        broken = True
        res += fields[i] + " "
      else:
        res += fields[i] + " " * (self.widths[i] - len(fields[i]))
    return res + "\n"


# Makes sure that arguments specified by the parser and not supplied
# by the user.
def check_args(args, parser):
  found, _ = parser.parse_known_args(args)
  offending = list(vars(found).keys())
  if len(offending) > 0:
    print(
      "uxy: argument '%s' is overriden by uxy, cannot be set by the user" %
        offending[0],
      file=sys.stderr)
    sys.exit(1)


################################################################################
# Generic UXY tools.
################################################################################


def uxy_cmd_align(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('align', help="align columns")
  args = parser.parse_args(args)

  s = trim_newline(sys.stdin.readline())
  fmt = Format(s)
  records = []
  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    fmt.adjust(fields)
    records.append(fields)
  writeout(fmt.render())
  for r in records:
    writeout(fmt.render(r))


def uxy_cmd_import(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('import',
    help="convert arbitrary input to UXY")
  subp.add_argument('header', help="UXY header")
  subp.add_argument('regexp', help="regexp to parse the input lines")
  args = parser.parse_args(args)

  # Use the supplied format.
  fmt = Format(args.header)
  writeout(fmt.render())
  # Parse the data.
  regexp = re.compile(args.regexp)
  for ln in sys.stdin:
    m = regexp.match(trim_newline(ln))
    # Non-matching lines are ignored.
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    writeout(fmt.render(fields))


def uxy_cmd_grep(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('grep', help="find regexp in UXY")
  subp.add_argument('regexp', help="regexp to parse the input lines")
  subp.add_argument('field', nargs='?', help="UXY field to match")
  args = parser.parse_args(args)

  regexp = re.compile(args.regexp)
  # Use the old headers.
  s = trim_newline(sys.stdin.readline())
  fmt = Format(s)
  writeout(fmt.render())
  # Process the data.
  for ln in sys.stdin:
    match = False
    fields = split_fields(trim_newline(ln))
    for i in range(0, len(fields)):
      if args.field == None or args.field == fmt.fields[i]:
        m = regexp.search(decode_field(fields[i]))
        if m:
          match = True
          break
    if match:
      writeout(fmt.render(fields))


def uxy_cmd_fmt(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('fmt',
    help="reformat UXY data")
  subp.add_argument('header', help="new UXY header")
  args = parser.parse_args(args)

  # Use the supplied format.
  fmt = Format(args.header)
  newhdr = split_fields(args.header)
  writeout(fmt.render())
  # Read the old format.
  s = trim_newline(sys.stdin.readline())
  oldhdr = split_fields(s)
  # Process the data.
  for ln in sys.stdin:
    oldfields = split_fields(trim_newline(ln))
    newfields = ['""'] * len(newhdr)
    for i in range(0, len(oldfields)):
      if i >= len(oldhdr):
        break
      oldname = oldhdr[i]
      if oldname not in newhdr:
        continue
      newfields[newhdr.index(oldname)] = oldfields[i]
    writeout(fmt.render(newfields))


def uxy_cmd_trim(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('trim',
    help="trim long fields to fit into columns")
  args = parser.parse_args(args)

  # Read the headers.
  s = trim_newline(sys.stdin.readline())
  fmt = Format(s)
  # Adjust the column widths so that at least quoted elipsis fits in.
  for i in range(0, len(fmt.widths) - 1):
    fmt.widths[i] = max(fmt.widths[i], 6)
  writeout(fmt.render())
  # Process the records.
  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    # Get rid of unnamed fields.
    fields = fields[:len(fmt.widths)]
    # Trim the long fields. Last field is never trimmed.
    for i in range(0, len(fields) - 1):
      if len(fields[i]) > fmt.widths[i] - 1:
        if fields[i].startswith('"') and fields[i].endswith('"'):
            fields[i] = '"' + fields[i][1:fmt.widths[i] - 6] + '..."'
            if fields[i] == '"..."':
              fields[i] = '...'
        else:
            fields[i] = fields[i][:fmt.widths[i] - 4] + "..."
    writeout(fmt.render(fields))


################################################################################
# CSV
################################################################################


def uxy_cmd_from_csv(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('from-csv',
    help="convert CSV to UXY")
  args = parser.parse_args(args)

  # Read the headers
  ln = trim_newline(sys.stdin.readline())
  r = csv.reader(io.StringIO(ln))
  for fields in r:
    fields = " ".join([encode_field(f) for f in fields])
    fmt = Format(fields)
    writeout(fields + "\n")
  for ln in sys.stdin:
    r = csv.reader(io.StringIO(trim_newline(ln)))
    for fields in r:
      fields = [encode_field(f) for f in fields]
      writeout(fmt.render(fields))
    
  
def uxy_cmd_to_csv(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('to-csv',
    help="convert UXY to CSV")
  args = parser.parse_args(args)

  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    fields = [decode_field(f) for f in fields]
    buf = io.StringIO()
    w = csv.writer(buf)
    w.writerow(fields)
    writeout(buf.getvalue())


################################################################################
# JSON
################################################################################        


def uxy_cmd_from_json(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('from-json',
    help="convert JSON to UXY")
  args = parser.parse_args(args)

  # Read the entire input.
  s = ""
  for ln in sys.stdin:
    s += ln
  root = json.loads(s)
  # Normalize the JSON. Collect the field names along the way.
  fields = {}
  if not isinstance(root, list):
    root = [root]
  for i in range(0, len(root)):
    if not isinstance(root[i], dict):
      root[i] = {"COL1": root[i]}
    for k, _ in root[i].items():
      fields[k] = None
  # Fields will go to the output in alphabetical order.
  fields = sorted(fields)
  # Collect the data. At the same time adjust the format sa that data fit in.
  fmt = Format(" ".join([encode_field(f) for f in fields]))
  records = []
  for i in range(0, len(root)):
    record = []
    for f in fields:
      if f in root[i]:
        record.append(encode_field(str(root[i][f])))
      else:
        record.append('""')
    fmt.adjust(record)
    records.append(record)
  # Write the result to output.
  writeout(fmt.render())
  for r in records:
    writeout(fmt.render(r))


def uxy_cmd_to_json(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('to-json',
    help="convert UXY to JSON")
  args = parser.parse_args(args)

  s = trim_newline(sys.stdin.readline())
  hdr = split_fields(s)
  res = []
  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    item = {}
    for i in range(0, len(fields)):
      item[decode_field(hdr[i])] = decode_field(fields[i])
    res.append(item)
  writeout(json.dumps(res, indent=4) + "\n")


################################################################################
# YAML
################################################################################


def uxy_cmd_from_yaml(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('from-yaml',
    help="convert YAML to UXY")
  args = parser.parse_args(args)

  # Read the entire input.
  s = ""
  for ln in sys.stdin:
    s += ln
  root = yaml.load(s, Loader=yaml.FullLoader)
  # Normalize the dict. Collect the field names along the way.
  fields = {}
  if not isinstance(root, list):
    root = [root]
  for i in range(0, len(root)):
    if not isinstance(root[i], dict):
      root[i] = {"COL1": root[i]}
    for k, _ in root[i].items():
      fields[k] = None
  # Fields will go to the output in alphabetical order.
  fields = sorted(fields)
  # Collect the data. At the same time adjust the format sa that data fit in.
  fmt = Format(" ".join([encode_field(f) for f in fields]))
  records = []
  for i in range(0, len(root)):
    record = []
    for f in fields:
      if f in root[i]:
        record.append(encode_field(str(root[i][f])))
      else:
        record.append('""')
    fmt.adjust(record)
    records.append(record)
  # Write the result to output.
  writeout(fmt.render())
  for r in records:
    writeout(fmt.render(r))


def uxy_cmd_to_yaml(parser, args, uxy_args):
  subp = parser.add_subparsers().add_parser('to-yaml',
    help="convert UXY to YAML")
  args = parser.parse_args(args)

  s = trim_newline(sys.stdin.readline())
  hdr = split_fields(s)
  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    item = {}
    for i in range(0, len(fields)):
      item[decode_field(hdr[i])] = decode_field(fields[i])
    writeout(yaml.dump([item], default_flow_style=False))


################################################################################
# Wrappers for UNIX tools.
################################################################################


def uxy_cmd_du(parser, args, uxy_args):
  proc = subprocess.Popen(['du'] + args[1:], stdout=subprocess.PIPE)
  regexp = re.compile(r'\s*([^\s]*)\s+(.*)')
  fmt = Format("USAGE    FILE")
  writeout(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    writeout(fmt.render(fields))


def uxy_cmd_ls(parser, args, uxy_args):
  parser = argparse.ArgumentParser(add_help=False)
  parser.add_argument("--author", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-b", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--escape", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-C", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--color", nargs="?", default=argparse.SUPPRESS)
  parser.add_argument("-D", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-f", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--format", nargs="?", default=argparse.SUPPRESS)
  parser.add_argument("--full-time", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-g", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-h", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--human-readable", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--si", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-G", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--no-group", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-i", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--inode", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-k", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--kibibytes", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-l", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-m", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-N", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--literal", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-o", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-q", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--hide-control-chars", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-Q", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--quote-name", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--quoting-style", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("-s", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--time", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("--time-style", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("-T", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("--tabsize", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("-w", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("--width", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("-x", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-Z", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--context", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-1", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--help", action="store_true", default=argparse.SUPPRESS)
  check_args(args, parser)

  if uxy_args.long:
    fmtargs = ['-lNisZw0', '--time-style=full-iso']
    regexp = re.compile(r'\s*([^\s]*)\s+([^\s]*)\s+(.)([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+(.*)')
    fmt = Format("INODE   BLOCKS TYPE PERMISSIONS LINKS OWNER      GROUP      CONTEXT SIZE         TIME                                  NAME")
  else:
    fmtargs = ['-lNw0', '--time-style=full-iso']
    regexp = re.compile(r'\s*(.)([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+(.*)')
    fmt = Format("TYPE PERMISSIONS LINKS OWNER      GROUP      SIZE         TIME                                  NAME")

  proc = subprocess.Popen(['ls'] + fmtargs + args[1:], stdout=subprocess.PIPE)
  writeout(fmt.render())
  path = ""
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    if ln.startswith('total'):
      continue
    if ln == "":
      # When running with -R this is the name of the directory.
      ln = trim_newline(proc.stdout.readline().decode("utf-8"))
      if ln.endswith(":"):
        path = ln[:-1] + "/"
      continue
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups - 3):
      fields.append(encode_field(m.group(i)))
    # Convert to actual ISO8601 format.
    time = "%sT%s%s:%s" % (
      m.group(regexp.groups - 3),
      m.group(regexp.groups - 2),
      m.group(regexp.groups - 1)[:-2],
      m.group(regexp.groups - 1)[-2:])
    fields.append(encode_field(time))
    fields.append(encode_field(path + m.group(regexp.groups)))
    writeout(fmt.render(fields))


def uxy_cmd_lsof(parser, args, uxy_args):
  proc = subprocess.Popen(['lsof', '+c', '0'] + args[1:], stdout=subprocess.PIPE)
  hdr = trim_newline(proc.stdout.readline().decode("utf-8"))
  parts = re.split("(\s+)", hdr)
  pos = [len(p) for p in list(itertools.accumulate(parts))]
  r1 = re.compile(r'([^\s]*)\s+([^\s]*)')
  fmt = Format("COMMAND             PID    TID    USER           FD      TYPE    DEVICE             SIZEOFF   NODE       NAME")
  writeout(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    fields = []
    m = r1.match(ln[:pos[2]])
    if not m:
      continue
    fields.append(m.group(1))
    fields.append(m.group(2))
    fields.append(ln[pos[2]:pos[4]].strip())
    fields.append(ln[pos[4]:pos[6]].strip())
    fields.append(ln[pos[6]:pos[8] + 1].strip())
    fields.append(ln[pos[8] + 1:pos[10]].strip())
    fields.append(ln[pos[10]:pos[12]].strip())
    fields.append(ln[pos[12]:pos[14]].strip())
    fields.append(ln[pos[14]:pos[16]].strip())
    fields.append(ln[pos[16]:].strip())
    fields = [encode_field(f) for f in fields]
    writeout(fmt.render(fields))


def uxy_cmd_netstat(parser, args, uxy_args):
  proc = subprocess.Popen(['netstat', '--inet'] + args[1:], stdout=subprocess.PIPE)
  # Skip header line.
  proc.stdout.readline()
  hdr = trim_newline(proc.stdout.readline().decode("utf-8"))
  parts = re.split("(\s+)", hdr)
  pos = [len(p) for p in list(itertools.accumulate(parts))]
  fmt = Format("PROTO  RECVQ  SENDQ  LOCAL            REMOTE                      STATE")
  writeout(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    fields = []
    fields.append(ln[0:pos[0]].strip())
    fields.append(ln[pos[0]:pos[2]].strip())
    fields.append(ln[pos[2]:pos[4]].strip())
    fields.append(ln[pos[4]:pos[8]].strip())
    fields.append(ln[pos[8]:pos[13]].strip())
    fields.append(ln[pos[13]:].strip())
    fields = [encode_field(f) for f in fields]
    writeout(fmt.render(fields))


def uxy_cmd_ps(parser, args, uxy_args):
  parser = argparse.ArgumentParser(add_help=False)
  parser.add_argument("-c", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--context", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-f", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-F", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-j", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-l", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-M", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-o", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("-O", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("-y", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--cols", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("--columns", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("--forest", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("-H", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--headers", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--lines", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("--no-headers", action="store_true", default=argparse.SUPPRESS)
  parser.add_argument("--rows", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("--width", nargs=1, default=argparse.SUPPRESS)
  parser.add_argument("--help", nargs=1, default=argparse.SUPPRESS)
  check_args(args, parser)

  # TODO: This is better parsed as fixed-width fields.
  if uxy_args.long:
    fmtargs = ['-FMlww', '--no-headers']
    regexp = re.compile(r'\s*([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+(.*)')
    fmt = Format("CONTEXT        F  S  UID        PID    PPID    C  PRI  NI  ADDR  SZ        WCHAN    RSS     PSR  STIME   TTY    TIME       CMD")
  else:
    fmtargs = ['-ww', '--no-headers']
    regexp = re.compile(r'\s*([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+(.*)')
    fmt = Format("PID      TTY      TIME       CMD")

  proc = subprocess.Popen(['ps'] + fmtargs + args[1:], stdout=subprocess.PIPE)
  writeout(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    writeout(fmt.render(fields))


def uxy_cmd_top(parser, args, uxy_args):
  proc = subprocess.Popen(['top', '-bn1'] + args[1:], stdout=subprocess.PIPE)
  # Skip the summary.
  for i in range(0, 7):
    proc.stdout.readline()
  regexp = re.compile(r'\s*([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+(.*)')
  fmt = Format("PID    USER     PR   NI   VIRT     RES      SHR      S  CPU   MEM   TIME        COMMAND")
  writeout(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    writeout(fmt.render(fields))


def uxy_cmd_w(parser, args, uxy_args):
  proc = subprocess.Popen(['w', '-h'] + args[1:], stdout=subprocess.PIPE)
  regexp = re.compile(r'([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+(.*)')
  fmt = Format("USER     TTY    FROM    LOGIN    IDLE    JCPU    PCPU    WHAT")
  writeout(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    writeout(fmt.render(fields))


################################################################################
# Main.
################################################################################

def main():

  # Start by finding the subcommand and splitting args meant for uxy itself and
  # the arguments to be passed to the subcommand (which may be an arbitrary
  # UNIX tool with arbitrary arguments).
  idx = len(sys.argv)
  for i in range(1, len(sys.argv)):
    if not sys.argv[i].startswith("-"):
      idx = i
      break
  parser = argparse.ArgumentParser(prog="uxy",
    description="Tool to manipulate UXY data.")
  parser.add_argument('-l', '--long', action="store_true", default=False,
    help = "produce more data")
  parser.add_argument('subcommand', metavar="SUBCOMMAND",
    help = "subcommand to execute")
  uxy_args = parser.parse_args(sys.argv[1:idx + 1])
  subcommand = sys.argv[idx]
  args = sys.argv[idx:]
  subcommands = {
    "align": uxy_cmd_align,
    "du": uxy_cmd_du,
    "fmt": uxy_cmd_fmt,
    "from-csv": uxy_cmd_from_csv,
    "from-json": uxy_cmd_from_json,
    "from-yaml": uxy_cmd_from_yaml,
    "grep": uxy_cmd_grep,
    "import": uxy_cmd_import,
    "ls": uxy_cmd_ls,
    "lsof": uxy_cmd_lsof,
    "netstat": uxy_cmd_netstat,
    "ps": uxy_cmd_ps,
    "to-csv": uxy_cmd_to_csv,
    "to-json": uxy_cmd_to_json,
    "to-yaml": uxy_cmd_to_yaml,
    "top": uxy_cmd_top,
    "trim": uxy_cmd_trim,
    "w": uxy_cmd_w,
  }
  if subcommand not in subcommands:
    print("uxy: invalid subcommand '%s' (choose from: %s)" % (subcommand,
      ", ".join(subcommands.keys())), file=sys.stderr)
    sys.exit(1)
  parser = argparse.ArgumentParser(prog="uxy",
    description="Tool to manipulate UXY data.")
  subcommands[subcommand](parser, args, uxy_args)


if __name__ == "__main__":
    main()
