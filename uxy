#!/usr/bin/python3

#  Copyright (c) 2019 Martin Sustrik
#
#  Permission is hereby granted, free of charge, to any person obtaining a copy
#  of this software and associated documentation files (the "Software"),
#  to deal in the Software without restriction, including without limitation
#  the rights to use, copy, modify, merge, publish, distribute, sublicense,
#  and/or sell copies of the Software, and to permit persons to whom
#  the Software is furnished to do so, subject to the following conditions:
#  The above copyright notice and this permission notice shall be included
#  in all copies or substantial portions of the Software.
#  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
#  THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
#  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
#  IN THE SOFTWARE.

import argparse
import csv
import io
import itertools
import json
import re
import subprocess
import sys
import unicodedata
import yaml


################################################################################
# Infrastructure
################################################################################


def trim_newline(s):
  if s.endswith('\n'):
    return s[:-1]
  return s


ESCAPE_SEQUENCES1 = {
  't':  '\t',
  'n':  '\n',
  '"':  '"',
  '\\': '\\',
}


ESCAPE_SEQUENCES2 = {
  '\t':  't',
  '\n':  'n',
  '"':  '"',
  '\\': '\\',
}


# Convert uxy field into a string.
def decode_field(s):
  # Replace control characters by question marks.
  s = "".join((c if unicodedata.category(c)[0] != "C" else '?') for c in s)
  if not (s.startswith('"') and s.endswith('"')):
    return s
  # Quoted field.
  s = s[1:-1]
  # Exapnd escape sequences.
  f = ""
  j = 0
  while j < len(s):
    if s[j] == '\\':
      if j + 1 >= len(s):
        f += "?"
        j += 1;
        continue
      if s[j + 1] not in ESCAPE_SEQUENCES1:
        f += "?"
        j += 2
        continue
      f += ESCAPE_SEQUENCES1[s[j + 1]]
      j += 2
      continue
    f += s[j]
    j += 1
  return f


# Convert arbitrary string into a uxy field.
def encode_field(s):
  # Empty string converts to "".
  if s == "":
    return '""  '
  # Check whether the string contains any special characters.
  special = False
  if '"' in s or ' ' in s:
    special = True
  else:
    for c in s:
      if unicodedata.category(c)[0] == "C":
        special = True
        break
  if not special:
    return s
  # Quoted field is needed.
  f = '"'
  for c in s:
    if c in ESCAPE_SEQUENCES2:
      f += ESCAPE_SEQUENCES2[c]
      continue
    f += c
  return f + '"'

UNQUOTED = 1
QUOTED = 2
ESCAPE = 3
TRAILING = 4

# Given a line, this function splits it into individual uxy fields and field widths.
def split_fields_widths(s):
  fields = []
  widths = []
  state = TRAILING
  field = ""
  width = 0
  for c in s:
    if state == UNQUOTED:
      if c == ' ':
        width += 1
        state = TRAILING
      else:
        field += c
        width += 1
    elif state == QUOTED:
      if c == "\\":
        field += c
        width += 1
        state = ESCAPE
      elif c == '"':
        field += c
        width += 1
        state = TRAILING
      else:
        field += c
        width += 1      
    elif state == ESCAPE:
      field += c
      width += 1
      state = QUOTED
    elif state == TRAILING:
      if c == " ":
        width += 1
      else:
        if len(field) > 0:
          fields.append(field)
          widths.append(width)
        field = c
        width = 1
        if c == '"':
          state = QUOTED
        else:
          state = UNQUOTED
  if len(field) > 0:
    fields.append(field)
    widths.append(width)
  return (fields, widths)


# Given a line, this function splits it into individual uxy fields.
def split_fields(s):
  fields, _ = split_fields_widths(s)
  return fields


class Format:

  # Create a format from a list of fields.
  # The values of the fields will be used as column names.
  def __init__(self, fmt):
    self.fields, self.widths = split_fields_widths(fmt)

  # Adjust the format so that the fields fit in.
  def adjust(self, fields):
    for i in range(0, len(fields)):
       self.widths[i] = max(self.widths[i], len(fields[i]) + 1)

  # Renders the supplied fields according to the format.
  # If fields is None, it renders the header itself.
  def render(self, fields=None):
    if fields == None:
      fields = self.fields
    broken = False
    res = ""
    for i in range(0, len(fields)):
      if broken or len(fields[i]) + 1 > self.widths[i]:
        broken = True
        res += fields[i] + " "
      else:
        res += fields[i] + " " * (self.widths[i] - len(fields[i]))
    return res + "\n"


################################################################################
# Generic UXY tools.
################################################################################


def uxy_cmd_align(args):
  s = trim_newline(sys.stdin.readline())
  fmt = Format(s)
  records = []
  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    fmt.adjust(fields)
    records.append(fields)
  sys.stdout.write(fmt.render())
  for r in records:
    sys.stdout.write(fmt.render(r))


def uxy_cmd_re(args):
  # Use the supplied format.
  fmt = Format(args.header)
  sys.stdout.write(fmt.render())
  # Parse the data.
  regexp = re.compile(args.regexp)
  for ln in sys.stdin:
    m = regexp.match(trim_newline(ln))
    # Non-matching lines are ignored.
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    sys.stdout.write(fmt.render(fields))


def uxy_cmd_reformat(args):
  # Use the supplied format.
  fmt = Format(args.header)
  newhdr = split_fields(args.header)
  sys.stdout.write(fmt.render())
  # Read the old format.
  s = trim_newline(sys.stdin.readline())
  oldhdr = split_fields(s)
  # Process the data.
  for ln in sys.stdin:
    oldfields = split_fields(trim_newline(ln))
    newfields = ['""'] * len(newhdr)
    for i in range(0, len(oldfields)):
      if i >= len(oldhdr):
        break
      oldname = oldhdr[i]
      if oldname not in newhdr:
        continue
      newfields[newhdr.index(oldname)] = oldfields[i]
    sys.stdout.write(fmt.render(newfields))


def uxy_cmd_trim(args):
  # Read the headers.
  s = trim_newline(sys.stdin.readline())
  fmt = Format(s)
  # Adjust the column widths so that at least quoted elipsis fits in.
  for i in range(0, len(fmt.widths) - 1):
    fmt.widths[i] = max(fmt.widths[i], 6)
  sys.stdout.write(fmt.render())
  # Process the records.
  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    # Get rid of unnamed fields.
    fields = fields[:len(fmt.widths)]
    # Trim the long fields. Last field is never trimmed.
    for i in range(0, len(fields) - 1):
      if len(fields[i]) > fmt.widths[i] - 1:
        if fields[i].startswith('"') and fields[i].endswith('"'):
            fields[i] = '"' + fields[i][1:fmt.widths[i] - 6] + '..."'
            if fields[i] == '"..."':
              fields[i] = '...'
        else:
            fields[i] = fields[i][:fmt.widths[i] - 4] + "..."
    sys.stdout.write(fmt.render(fields))


################################################################################
# CSV
################################################################################


def uxy_cmd_from_csv(args):
  # Read the headers
  ln = trim_newline(sys.stdin.readline())
  r = csv.reader(io.StringIO(ln))
  for fields in r:
    fields = " ".join([encode_field(f) for f in fields])
    fmt = Format(fields)
    sys.stdout.write(fields + "\n")
  for ln in sys.stdin:
    r = csv.reader(io.StringIO(trim_newline(ln)))
    for fields in r:
      fields = [encode_field(f) for f in fields]
      sys.stdout.write(fmt.render(fields))
    

def uxy_cmd_to_csv(args):
  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    fields = [decode_field(f) for f in fields]
    buf = io.StringIO()
    w = csv.writer(buf)
    w.writerow(fields)
    sys.stdout.write(buf.getvalue())
    #print(fields)


################################################################################
# JSON
################################################################################        


def uxy_cmd_from_json(args):
  # Read the entire input.
  s = ""
  for ln in sys.stdin:
    s += ln
  root = json.loads(s)
  # Normalize the JSON. Collect the field names along the way.
  fields = {}
  if not isinstance(root, list):
    root = [root]
  for i in range(0, len(root)):
    if not isinstance(root[i], dict):
      root[i] = {"COL1": root[i]}
    for k, _ in root[i].items():
      fields[k] = None
  # Fields will go to the output in alphabetical order.
  fields = sorted(fields)
  # Collect the data. At the same time adjust the format sa that data fit in.
  fmt = Format(" ".join([encode_field(f) for f in fields]))
  records = []
  for i in range(0, len(root)):
    record = []
    for f in fields:
      if f in root[i]:
        record.append(encode_field(str(root[i][f])))
      else:
        record.append('""')
    fmt.adjust(record)
    records.append(record)
  # Write the result to output.
  sys.stdout.write(fmt.render())
  for r in records:
    sys.stdout.write(fmt.render(r))


def uxy_cmd_to_json(args):
  s = trim_newline(sys.stdin.readline())
  hdr = split_fields(s)
  res = []
  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    item = {}
    for i in range(0, len(fields)):
      item[decode_field(hdr[i])] = decode_field(fields[i])
    res.append(item)
  sys.stdout.write(json.dumps(res, indent=4) + "\n")


################################################################################
# YAML
################################################################################

def uxy_cmd_from_yaml(args):
  # Read the entire input.
  s = ""
  for ln in sys.stdin:
    s += ln
  root = yaml.load(s, Loader=yaml.FullLoader)
  # Normalize the dict. Collect the field names along the way.
  fields = {}
  if not isinstance(root, list):
    root = [root]
  for i in range(0, len(root)):
    if not isinstance(root[i], dict):
      root[i] = {"COL1": root[i]}
    for k, _ in root[i].items():
      fields[k] = None
  # Fields will go to the output in alphabetical order.
  fields = sorted(fields)
  # Collect the data. At the same time adjust the format sa that data fit in.
  fmt = Format(" ".join([encode_field(f) for f in fields]))
  records = []
  for i in range(0, len(root)):
    record = []
    for f in fields:
      if f in root[i]:
        record.append(encode_field(str(root[i][f])))
      else:
        record.append('""')
    fmt.adjust(record)
    records.append(record)
  # Write the result to output.
  sys.stdout.write(fmt.render())
  for r in records:
    sys.stdout.write(fmt.render(r))


def uxy_cmd_to_yaml(args):
  s = trim_newline(sys.stdin.readline())
  hdr = split_fields(s)
  res = []
  for ln in sys.stdin:
    fields = split_fields(trim_newline(ln))
    item = {}
    for i in range(0, len(fields)):
      item[decode_field(hdr[i])] = decode_field(fields[i])
    res.append(item)
  sys.stdout.write(yaml.dump(res, default_flow_style=False))


################################################################################
# Wrappers for UNIX tools.
################################################################################


def uxy_cmd_du(args, uargs):
  proc = subprocess.Popen(['du'] + uargs, stdout=subprocess.PIPE)
  regexp = re.compile(r'\s*([^\s]*)\s+(.*)')
  fmt = Format("USAGE    FILE")
  sys.stdout.write(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    sys.stdout.write(fmt.render(fields))


def uxy_cmd_ls(args, uargs):
  proc = subprocess.Popen(
    ['ls','-l', '--time-style=full-iso'] + uargs,
    stdout=subprocess.PIPE)
  regexp = re.compile(r'(.)([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*\s+[^\s]*\s+[^\s]*)\s+(.*)')
  fmt = Format("TYPE PERMISSIONS LINKS OWNER      GROUP      SIZE         TIME                                  NAME")
  sys.stdout.write(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    if ln.startswith('total'):
      continue
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    sys.stdout.write(fmt.render(fields))


def uxy_cmd_lsof(args, uargs):
  proc = subprocess.Popen(['lsof', '+c', '0'] + uargs, stdout=subprocess.PIPE)
  hdr = trim_newline(proc.stdout.readline().decode("utf-8"))
  parts = re.split("(\s+)", hdr)
  pos = [len(p) for p in list(itertools.accumulate(parts))]
  r1 = re.compile(r'([^\s]*)\s+([^\s]*)')
  fmt = Format("COMMAND             PID    TID    USER           FD      TYPE    DEVICE             SIZEOFF   NODE       NAME")
  sys.stdout.write(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    fields = []
    m = r1.match(ln[:pos[2]])
    if not m:
      continue
    fields.append(m.group(1))
    fields.append(m.group(2))
    fields.append(ln[pos[2]:pos[4]].strip())
    fields.append(ln[pos[4]:pos[6]].strip())
    fields.append(ln[pos[6]:pos[8] + 1].strip())
    fields.append(ln[pos[8] + 1:pos[10]].strip())
    fields.append(ln[pos[10]:pos[12]].strip())
    fields.append(ln[pos[12]:pos[14]].strip())
    fields.append(ln[pos[14]:pos[16]].strip())
    fields.append(ln[pos[16]:].strip())
    fields = [encode_field(f) for f in fields]
    sys.stdout.write(fmt.render(fields))


def uxy_cmd_netstat(args, uargs):
  proc = subprocess.Popen(['netstat', '--inet'] + uargs, stdout=subprocess.PIPE)
  # Skip header line.
  proc.stdout.readline()
  hdr = trim_newline(proc.stdout.readline().decode("utf-8"))
  parts = re.split("(\s+)", hdr)
  pos = [len(p) for p in list(itertools.accumulate(parts))]
  fmt = Format("PROTO  RECVQ  SENDQ  LOCAL            REMOTE                      STATE")
  sys.stdout.write(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    fields = []
    fields.append(ln[0:pos[0]].strip())
    fields.append(ln[pos[0]:pos[2]].strip())
    fields.append(ln[pos[2]:pos[4]].strip())
    fields.append(ln[pos[4]:pos[8]].strip())
    fields.append(ln[pos[8]:pos[13]].strip())
    fields.append(ln[pos[13]:].strip())
    fields = [encode_field(f) for f in fields]
    sys.stdout.write(fmt.render(fields))


def uxy_cmd_ps(args, uargs):
  proc = subprocess.Popen(['ps'] + uargs, stdout=subprocess.PIPE)
  regexp = re.compile(r'\s*([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+(.*)')
  fmt = Format("PID      TTY      TIME       CMD")
  sys.stdout.write(fmt.render())
  # Ignore the header file.
  proc.stdout.readline()
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    sys.stdout.write(fmt.render(fields))


def uxy_cmd_top(args, uargs):
  proc = subprocess.Popen(['top', '-bn1'] + uargs, stdout=subprocess.PIPE)
  # Skip the summary.
  for i in range(0, 7):
    proc.stdout.readline()
  regexp = re.compile(r'\s*([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+(.*)')
  fmt = Format("PID    USER     PR   NI   VIRT     RES      SHR      S  CPU   MEM   TIME        COMMAND")
  sys.stdout.write(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    sys.stdout.write(fmt.render(fields))


def uxy_cmd_w(args, uargs):
  proc = subprocess.Popen(['w', '-h'] + uargs, stdout=subprocess.PIPE)
  regexp = re.compile(r'([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+([^\s]*)\s+(.*)')
  fmt = Format("USER     TTY    FROM    LOGIN    IDLE    JCPU    PCPU    WHAT")
  sys.stdout.write(fmt.render())
  for ln in proc.stdout:
    ln = trim_newline(ln.decode("utf-8"))
    m = regexp.match(ln)
    if not m:
      continue
    fields = []
    for i in range(1, regexp.groups + 1):
      fields.append(encode_field(m.group(i)))
    sys.stdout.write(fmt.render(fields))


################################################################################
# Main.
################################################################################


def main():
  
  parser = argparse.ArgumentParser(prog="uxy",
    description="Tool to manipulate UXY data.")
  subparsers = parser.add_subparsers()

  p = subparsers.add_parser('align', help="align columns")
  p.set_defaults(func=uxy_cmd_align)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('du', help="wrapper for 'du' command")
  p.set_defaults(func=uxy_cmd_du)

  p = subparsers.add_parser('from-csv', help="convert CSV to UXY")
  p.set_defaults(func=uxy_cmd_from_csv)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('from-json', help="convert JSON to UXY")
  p.set_defaults(func=uxy_cmd_from_json)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('from-yaml', help="convert YAML to UXY")
  p.set_defaults(func=uxy_cmd_from_yaml)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('ls', help="wrapper for 'ls' command")
  p.set_defaults(func=uxy_cmd_ls)

  p = subparsers.add_parser('lsof', help="wrapper for 'lsof' command")
  p.set_defaults(func=uxy_cmd_lsof)

  p = subparsers.add_parser('netstat', help="wrapper for 'netstat' command")
  p.set_defaults(func=uxy_cmd_netstat)

  p = subparsers.add_parser('ps', help="wrapper for 'ps' command")
  p.set_defaults(func=uxy_cmd_ps)

  p = subparsers.add_parser('re', help="convert arbitrary input to UXY")
  p.add_argument('header', help="UXY header")
  p.add_argument('regexp', help="regexp to parse the input lines")
  p.set_defaults(func=uxy_cmd_re)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('reformat', help="reformat UXY data")
  p.add_argument('header', help="new UXY header")
  p.set_defaults(func=uxy_cmd_reformat)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('to-csv', help="convert UXY to CSV")
  p.set_defaults(func=uxy_cmd_to_csv)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('to-json', help="convert UXY to JSON")
  p.set_defaults(func=uxy_cmd_to_json)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('to-yaml', help="convert UXY to YAML")
  p.set_defaults(func=uxy_cmd_to_yaml)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('top', help="wrapper for 'top' command")
  p.set_defaults(func=uxy_cmd_top)

  p = subparsers.add_parser('trim',
    help="trim long fields to fit into columns")
  p.set_defaults(func=uxy_cmd_trim)
  p.set_defaults(no_unknown_args=True)

  p = subparsers.add_parser('w', help="wrapper for 'w' command")
  p.set_defaults(func=uxy_cmd_w)

  # There must be a subcommand.
  if len(sys.argv) <= 1:
    parser.print_help()
    sys.exit(1)
  # Do liberal parsing of the arguments to get the subcommand.
  args, uargs = parser.parse_known_args(sys.argv[1:])
  # If required by the subcmmand, do strict parsing.
  if "no_unknown_args" in args and args.no_unknown_args:
    args = parser.parse_args(sys.argv[1:])
    args.func(args)
  else:
    args.func(args, uargs)

if __name__ == "__main__":
    main()
